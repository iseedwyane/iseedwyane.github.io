<!DOCTYPE html>
<html><head>
<style>
body {
  margin-top: 50px;
  margin-bottom: 50px;
  margin-left: 80px;
  margin-right: 80px;
}
p { 
  text-align: justify;
  font-size: 11pt;
  line-height: 1.4;
}

p.padding {
  padding-left: 10px;
}

ul { 
  text-align: justify;
  font-size: 11pt;
  line-height: 1.45;
}

a:link {
  color:rgb(158, 3, 3);
  background-color: transparent;
  text-decoration: none;
}

a:visited {
  color: rgb(158, 3, 3);
  background-color: transparent;
  text-decoration: none;
}

.section {max-width:1024px}
</style>
<meta name="msvalidate.01" content="F09EB454EEBF59AD68CB64C1A341AA9A" />
<meta name="baidu-site-verification" content="Ctys5yXPkU" />
<meta name="google-site-verification" content="9qnP6wIE8rh3TwMVrb84fWPqg9A_nDYEL3D6NGDjpwU" />
<meta name="keywords" content="Zengyi Qin, Zengyi Qin, Zengyi Qin, Zengyi Qin, Zengyi Qin">
<title>Zengyi Qin | MIT</title>
<meta charset="utf-8">
</head>

<body text="#444444" link="#444444" leftmargin="40" bgcolor="#FFFFFF">

<div class="section">
<table width="100%">
<tr>
<td width="25%">
<p align="center"><font face="Verdana"><img src="figures/zengyi.jpg" border="0" width="256"></font></p>
</td>
<td width="3%"></td>
<td width="72%">
<h2><font face="Verdana">Zengyi Qin 秦增益</h2>
<p><font face="Verdana"><a href="https://github.com/Zengyi-Qin/zengyi-qin.github.io/raw/master/CV_Zengyi.pdf">CV</a> | <a href="https://scholar.google.com/citations?user=lwwVd7sAAAAJ">Google Scholar</a> | <a href="https://github.com/Zengyi-Qin">Github</a></font></p>
<p><font face="Verdana">qinzy [at] mit.edu</font></p>
</td>
</tr>
</table>
</div>

<div class="section">
<p><font face="Verdana">I am a second-year graduate student at <a href="https://www.mit.edu/">Massachusetts Institute of Technology</a> advised by <a href="https://chuchu.mit.edu/">Prof. Chuchu Fan</a>. I obtained my B.E. degree of Electronic Engineering at <a href="https://www.tsinghua.edu.cn/en/">Tsinghua University</a>. <!--I am passionate about computer vision, robotics, safe and intelligent autonomous systems, and general artificial intelligence.-->
</font></p>
</div>


<div class="section">
<h3><font face="Verdana">Experiences</h3>
<p><font face="Verdana">
<ul>
<li><b>Massachusetts Institute of Technology</b>, 2020 - now <br> Graduate student in <a href="https://realm.mit.edu/">Reliable Autonomous Systems Lab at MIT (REALM)</a> <br> Advisor: <a href="https://chuchu.mit.edu/">Prof. Chuchu Fan</a></li>
</ul>
<ul>
<li><b>Tsinghua University</b>, 2016 - 2020 <br>Bachelor of Engineering, Electronic Engineering <br> Advisor: <a href="https://scholar.google.com/citations?user=A1gA9XIAAAAJ&hl=en">Prof. Jiansheng Chen</a></li>
</ul>
<ul>
<li><b>Stanford University</b>, Summer 2019 <br> Visiting researcher at <a href="http://svl.stanford.edu/people">Stanford Vision and Learning Lab (SVL)</a> <br> Advisor: <a href="http://svl.stanford.edu/people/">Prof. Silvio Savarese</a> and <a href="https://profiles.stanford.edu/fei-fei-li">Prof. Fei-Fei Li</a></li>
</ul>
<ul>
<li><b>Microsoft Research Asia</b>, 2018 - 2019 <br> Research intern at <a href="https://www.microsoft.com/en-us/research/group/media-computing-group/">Media Computing Group</a> <br> Advisor: <a href="https://jingluw.github.io/">Dr. Jinglu Wang</a> and <a href="https://www.microsoft.com/en-us/research/people/yanlu/">Dr. Yan Lu</a>
</ul>
</font></p>
</div>


<div class="section">
<h3><font face="Verdana">Publications</h3>
<table width="100%">

<!-- MONOGRNET-TPAMI -->
<tr>
<td width="25%" valign="top"><p><img src="figures/monogrnet_pami.PNG" alt="" style="border-style: none" width="250" align="top"></p></td>
<td width="75%" valign="top">
<p class="padding"><font face="Verdana">
<b>MonoGRNet: A General Framework for Monocular 3D Object Detection</b><br>
<b>Zengyi Qin</b>, Jinglu Wang and Yan Lu<br>
<i>The IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>TPAMI</b>), 2021</i><br>
</p>
<p class="padding"><font face="Verdana">A general monocular 3D object detection framework that flexibly adapts to both fully and weakly supervised learning, which alleviates the need of extensive 3D labels and only requires ground truth 2D bounding boxes during training.
</p>
<p class="padding"><font face="Verdana">
<a href="https://ieeexplore.ieee.org/document/9409679">paper</a>
</p></td>
</tr>
<tr><td><br></td></tr>


<!-- Reactive -->
<tr>
<td width="25%" valign="top"><p><video autoplay="" class="center" loop="" muted="" playsinline="" style="display:block; margin: 0 auto;" width="250"><source src="figures/reactive.mp4" style="display: block; margin-left: auto; margin-right: auto; width:250px" type="video/mp4" /></video></p></td>
<td width="75%" valign="top">
<p class="padding"><font face="Verdana">
<b>Reactive and Safe Road User Simulations using Neural Barrier Certificate</b><br>
Yue Meng, <b>Zengyi Qin</b> and Chuchu Fan<br>
<i>The International Conference on Intelligent Robots and Systems (<b>IROS</b>), 2021</i><br>
</p>
<p class="padding"><font face="Verdana">Reactive and safe agent modelings are important for nowadays traffic simulator designs and safe planning applications. We propose a control barrier function-based method to simulate traffic agents that behave like humans or human controlled vehicles, which react to other road participants.
</p>
<p class="padding"><font face="Verdana">
<a href="">paper</a> | <a href="https://realm.mit.edu/reactive-agent-models">website</a>
</p></td>
</tr>
<tr><td><br></td></tr>


<!-- DCRL -->
<tr>
<td width="25%" valign="top"><p><img src="figures/dcrl.png" alt="" style="border-style: none" width="250" align="top"></p></td>
<td width="75%" valign="top">
<p class="padding"><font face="Verdana">
<b>Density Constrained Reinforcement Learning</b><br>
<b>Zengyi Qin</b>, Yuxiao Chen and Chuchu Fan<br>
<i>The International Conference on Machine Learning (<b>ICML</b>), 2021</i><br>
</p>
<p class="padding"><font face="Verdana">We study constrained reinforcement learning (CRL) from a novel perspective by setting constraints directly on state density functions, rather than the value functions considered by previous work. State density has a clear physical and mathematical interpretation, and is able to express a wide variety of constraints such as resource limits and safety requirements.
</p>
<p class="padding"><font face="Verdana">
<a href="https://arxiv.org/abs/2106.12764">paper</a> | <a href="https://github.com/Zengyi-Qin/dcrl">code</a> | <a href="http://realm.mit.edu/blog/density-constrained-reinforcement-learning">website</a>
</p></td>
</tr>
<tr><td><br></td></tr>


<!-- MACBF -->
<tr>
<td width="25%" valign="top"><p><img src="figures/macbf.gif" alt="" style="border-style: none" width="250" align="top"></p></td>
<td width="75%" valign="top">
<p class="padding"><font face="Verdana">
<b>Learning Safe Multi-agent Control with Decentralized Neural Barrier Certificates</b><br>
<b>Zengyi Qin</b>, Kaiqing Zhang, Yuxiao Chen, Jingkai Chen and Chuchu Fan<br>
<i>The International Conference on Learning Representations (<b>ICLR</b>), 2021</i><br>
</p>
<p class="padding"><font face="Verdana">We study the multi-agent safe control problem where agents should avoid any collision while reaching their goals. Our method can scale up to an arbitrarily large number of agents (e.g., >1000 in our experiments) and achieve a 99-100% safety rate.
</p>
<p class="padding"><font face="Verdana">
<a href="https://arxiv.org/abs/2101.05436">paper</a> | <a href="https://www.youtube.com/watch?v=k9ap_aUPNBk">video</a> | <a href="https://github.com/Zengyi-Qin/macbf">code</a> | <a href="https://realm.mit.edu/blog/learning-safe-multi-agent-control-decentralized-neural-barrier-certificates">website</a>
</p></td>
</tr>
<tr><td><br></td></tr>


<!-- REALSYN -->
<tr>
<td width="25%" valign="top"><p><img src="figures/controller_synthesis.PNG" alt="" style="border-style: none" width="250" align="top"></p></td>
<td width="75%" valign="top">
<p class="padding"><font face="Verdana">
<b>Controller synthesis for linear system with reach-avoid specifications</b><br>
Chuchu Fan, <b>Zengyi Qin</b>, Umang Mathur, Qiang Ning, Sayan Mitra, and Mahesh Viswanathan<br>
<i>IEEE Transactions on Automatic Control (<b>TAC</b>), 2021</i><br>
</p>
<p class="padding"><font face="Verdana">We address the problem of synthesizing provably correct controllers for linear systems with reach-avoid specifications. Our solution  decomposes the overall synthesis problem into two smaller and more tractable problems, achieving a 2-150 times speedup compared with the previous techniques.
</p>
<p class="padding"><font face="Verdana">
<a href="https://ieeexplore.ieee.org/document/9390193">paper</a>
</p></td>
</tr>
<tr><td><br></td></tr>


<!-- VS3D -->
<tr>
<td width="25%" valign="top"><p><img src="figures/vs3d.gif" alt="" style="border-style: none" width="250" align="top"></p></td>
<td width="75%" valign="top">
<p class="padding"><font face="Verdana">
<b>Weakly Supervised 3D Object Detection from Point Clouds</b><br>
<b>Zengyi Qin</b>, Jinglu Wang and Yan Lu<br>
<i>ACM Multimedia (<b>ACM MM</b>), 2020</i><br>
</p>
<p class="padding"><font face="Verdana">A state-of-the-art framework for weakly supervised 3D object detection from point clouds without using any ground truth 3D bounding box for training. The core of our method is the unsupervised 3D object proposal module and the cross-modal knowledge distillation strategy.
</p>
<p class="padding"><font face="Verdana">
<a href="https://arxiv.org/abs/2007.13970">paper</a> | <a href="https://github.com/Zengyi-Qin/Weakly-Supervised-3D-Object-Detection">code</a>
</p></td>
</tr>
<tr><td><br></td></tr>


<!-- PDoctor -->
<tr>
<td width="25%" valign="top"><p><img src="figures/pdoctor.PNG" alt="" style="border-style: none" width="250" align="top"></p></td>
<td width="75%" valign="top">
<p class="padding"><font face="Verdana">
<b>Learning fine-grained estimation of physiological states from coarse-grained labels by distribution restoration</b><br>
<b>Zengyi Qin</b>, Jiansheng Chen, Zhenyu Jiang, Xumin Yu, Chunhua Hu, Yu Ma, Suhua Miao and Rongsong Zhou, <i> <b>Scientific Reports</b>, 2020</i><br>
</p>
<p class="padding"><font face="Verdana">Our method allows machine learning algorithms to perform fine-grained estimation of physiological states (e.g., sleep depth) even if the training labels are coarse-grained.
</p>
<p class="padding"><font face="Verdana">
<a href="https://www.nature.com/articles/s41598-020-79007-5">paper</a> | <a href="https://github.com/Zengyi-Qin/fine-biostate">code</a>
</p></td>
</tr>
<tr><td><br></td></tr>
  

<!-- KETO -->
<tr>
<td width="25%" valign="top"><p><img src="figures/keto.gif" alt="" style="border-style: none" width="250" align="top"></p></td>
<td width="75%" valign="top">
<p class="padding"><font face="Verdana">
<b>KETO: Learning Keypoint Representations for Tool Manipulation</b><br>
<b>Zengyi Qin</b>, Kuan Fang, Yuke Zhu, Li Fei-Fei and Silvio Savarese<br>
<i>The International Conference on Robotics and Automation (<b>ICRA</b>), 2020</i><br>
</p>
<p class="padding"><font face="Verdana">KETO is a framework for robots to manipulate unseen objects as tools to complete diverse tasks. We proposed a method to learn the keypoint representations of objects, which simplify the manipulation task and improve the generality to novel objects.
</p>
<p class="padding"><font face="Verdana">
<a href="https://arxiv.org/abs/1910.11977">paper</a> | <a href="https://www.youtube.com/watch?v=hP2h53BHxE8">video</a> | <a href="https://sites.google.com/view/ke-to">website</a>
</p></td>
</tr>
<tr><td><br></td></tr>

<!-- TLNET -->
<tr>
<td width="25%" valign="top"><p><img src="figures/tlnet.jpg" alt="" style="border-style: none" width="250" align="top"></p></td>
<td width="75%" valign="top">
<p class="padding"><font face="Verdana">
<b>Triangulation Learning Network: from Monocular to Stereo 3D Object Detection</b><br>
<b>Zengyi Qin</b>, Jinglu Wang and Yan Lu<br>
<i>The International Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2019</i><br>
</p>
<p class="padding"><font face="Verdana">This is a pioneering work on stereo image based 3D object detection without calculating the pixel-level depth maps. We proposed a triangulation learning method to learn the object-level stereo geometric correspondence for 3D object detection.
</p>
<p class="padding"><font face="Verdana">
<a href="https://arxiv.org/abs/1906.01193">paper</a> | <a href="https://youtu.be/zcOXA83Uq8M">video</a> | <a href="https://github.com/Zengyi-Qin/TLNet">code</a> | <a href="https://sites.google.com/view/triangulation-learning">website</a>
</p></td>
</tr>
<tr><td><br></td></tr>


<!-- MONOGRNET -->
<tr>
<td width="25%" valign="top"><p><img src="figures/monogrnet.gif" alt="" style="border-style: none" width="250" align="top"></p></td>
<td width="75%" valign="top">
<p class="padding"><font face="Verdana">
<b>MonoGRNet: A Geometric Reasoning Network for Monocular 3D Object Localization</b><br>
<b>Zengyi Qin</b>, Jinglu Wang and Yan Lu<br>
<i>The Thirty-Third AAAI Conference on Artificial Intelligence (<b>AAAI</b>), 2019, <b>Oral Presentation, Acceptance Rate < 8% </b> </i><br>
</p>
<p class="padding"><font face="Verdana">A state-of-the-art monocular 3D object detection approach based on geometric reasoning. We proposed to decompose the whole task into four progressive sub-tasks that significantly facilitates the monocular 3D object detection.
</p>
<p class="padding"><font face="Verdana">
<a href="https://arxiv.org/abs/1811.10247">paper</a> | <a href="https://youtu.be/BJ1I56kxdk0">video</a> | <a href="https://github.com/Zengyi-Qin/MonoGRNet">code</a> | <a href="https://sites.google.com/view/monogrnet">website</a>
</p></td>
</tr>
<tr><td><br></td></tr>

<!-- SNET -->
<tr>
<td width="25%" valign="top"><p><img src="figures/snet.png" alt="" style="border-style: none" width="250" align="top"></p></td>
<td width="75%" valign="top">
<p class="padding"><font face="Verdana">
<b>sEMG based Tremor Severity Evaluation for Parkinson's Disease using a Light-weight CNN</b><br>
<b>Zengyi Qin<top>*</top></b>, Zhenyu Jiang<top>*</top>, Jiansheng Chen, Chunhua Hu and Yu Ma<br>
<i>IEEE Signal Processing Letters (<b>SPL</b>), 2019</i><br>
</p>
<p class="padding"><font face="Verdana">A machine learning framework to assist the diagnosis of Parkinson's Disease by assessing the pathological tremor. We proposed a light-weight convolutional neural network and a similarity learning strategy to handle the scarcity of medical data.
</p>
<p class="padding"><font face="Verdana">
<a href="https://ieeexplore.ieee.org/document/8661631">paper</a> | <a href="https://sites.google.com/view/semg-tremor">website</a>
</p></td>
</tr>
<tr><td><br></td></tr>

</table>
</div>

<div class="section">
<h3><font face="Verdana">Honors</h3>
<p><font face="Verdana">
<ul>
<li>MathWorks Fellowship, 2021</li>
<li>Fellowship of Stanford Undergraduate Visiting and Research Program (UGVR), 2019</li>
<li>The Award of Excellence in Microsoft Research Internship, 2019</li>
<li>The highest award of Beijing Challenge Cup (<span lang="zh-cn">首都大学生挑战杯特等奖</span>), 2019</li>
<li>The highest award of Tsinghua Challenge Cup (<span lang="zh-cn">清华大学挑战杯特等奖</span>), 2019</li>
<li>Comprehensive Excellence Scholarship, Tsinghua University, 2018</li>
<li>The First Prize of Microsoft Imagine Cup, China Finals, 2018</li>
<li>Chairman of Student association of Data Science and Machine Learning (DSML), Tsinghua University, 2018</li>
</ul>
</font></p>
</div>

</body></html>
